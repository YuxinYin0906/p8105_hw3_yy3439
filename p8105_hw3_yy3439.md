p8105_hw3_yy3439
================
2023-10-10

## Problem 1 (All Parts of Problem 1 are from the Solution Provided by Professor Goldsmith, only here for completion)

``` r
library(p8105.datasets)
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(ggridges)
library(patchwork)
library(ggplot2)
data("instacart")
```

``` r
instacart = 
  instacart |> 
  as_tibble()
```

``` r
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

    ## # A tibble: 134 × 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ℹ 124 more rows

``` r
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

| aisle                      | product_name                                  |    n | rank |
|:---------------------------|:----------------------------------------------|-----:|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |

``` r
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

| product_name     |     0 |     1 |     2 |     3 |     4 |     5 |     6 |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

## Problem 2

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

#### Tidying-up Data

``` r
brfss_smart2010 = 
  brfss_smart2010 |>
  janitor::clean_names()|> #format data to appropriate variable names 
  filter(topic == "Overall Health")|> #focus only on the "Overall Health"
  filter(response %in% c("Excellent","Very Good", "Good", "Fair", "Poor"))|> #include only responses from excellent to poor
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very Good", "Excellent"))) #relevel the responses as a factor from "Poor" to "Excellent"
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `response = forcats::fct_relevel(...)`.
    ## Caused by warning:
    ## ! 1 unknown level in `f`: Very Good

#### 2002 Unique Obervation States

``` r
states_2002<-brfss_smart2010 |>
  separate(locationdesc, into = c('state', 'location', sep = '-'))|>
  filter(year =='2002')|>
  group_by(state)|>
  summarise(distinct_location = n_distinct(location))|>
  filter(distinct_location > 6)|>
  knitr::kable()
```

    ## Warning: Expected 3 pieces. Additional pieces discarded in 908 rows [41, 42, 43, 44, 45,
    ## 46, 47, 48, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, ...].

``` r
states_2002
```

| state | distinct_location |
|:------|------------------:|
| FL    |                 7 |
| MA    |                 8 |
| NC    |                 7 |
| NJ    |                 8 |
| PA    |                10 |

#### 2010 Unique Obervation States

``` r
states_2010 <-brfss_smart2010 |>
  separate(locationdesc, into = c('state', 'location', sep = '-'))|>
  filter(year =="2010")|>
  group_by(state)|>
  distinct(location)|>
  summarise(distinct_location = n())|>
  filter(distinct_location > 6)|>
  knitr::kable()
```

    ## Warning: Expected 3 pieces. Additional pieces discarded in 908 rows [41, 42, 43, 44, 45,
    ## 46, 47, 48, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, ...].

``` r
states_2010
```

| state | distinct_location |
|:------|------------------:|
| CA    |                 9 |
| CO    |                 7 |
| FL    |                40 |
| MA    |                 9 |
| MD    |                11 |
| NC    |                12 |
| NE    |                10 |
| NJ    |                19 |
| NY    |                 9 |
| OH    |                 8 |
| PA    |                 7 |
| SC    |                 7 |
| TX    |                16 |
| WA    |                10 |

As shown in the above table, we have 5 states that have 7 or more
distinct locations： FL, MA, NC, NJ, and PA. Similarly, we have 14
states that have 7 or more distinct locations: CA, CO, FL, MA, MD, NC,
NE, NJ, NY, OH, PA, SC, TX, and WA.

#### Data_value

``` r
avrage_brfss <- brfss_smart2010|>
  filter(response == "Excellent")|>
  group_by(year, locationabbr)|>
  select(year,  state = locationabbr, response, data_value)|>
   summarise(
    avg_data_value = mean(data_value, na.rm = TRUE))
```

    ## `summarise()` has grouped output by 'year'. You can override using the
    ## `.groups` argument.

``` r
 avrage_brfss
```

    ## # A tibble: 443 × 3
    ## # Groups:   year [9]
    ##     year state avg_data_value
    ##    <int> <chr>          <dbl>
    ##  1  2002 AK              27.9
    ##  2  2002 AL              18.5
    ##  3  2002 AR              24.1
    ##  4  2002 AZ              24.1
    ##  5  2002 CA              22.7
    ##  6  2002 CO              23.1
    ##  7  2002 CT              29.1
    ##  8  2002 DC              29.3
    ##  9  2002 DE              20.9
    ## 10  2002 FL              25.7
    ## # ℹ 433 more rows

#### Spaghetti Plot

``` r
avg_excellent = ggplot(avrage_brfss, aes(x = year, y = avg_data_value, group = state))+
  geom_line(aes(color = state))+
  theme_minimal()+
  labs(title = "Average Value of Excellent Responses Over Years", x = "Year", y = "Average Value")
ggsave("average value of excellent.png", avg_excellent)
```

    ## Saving 7 x 5 in image

``` r
avg_excellent
```

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

#### Two Panel Plot

``` r
panel_brfss = brfss_smart2010|>
  filter(year%in% c(2006, 2010))|>
  filter(locationabbr == "NY")

data_value_dist = ggplot(panel_brfss, aes(x = response, y = data_value, fill = response))+
  geom_boxplot()+
  facet_grid(~year)+
  labs(
    title = "Data Value Distributions for the Year of 2006 and 2010",
    x = "Response",
    y = "Data Value"
  )
  
ggsave("data value distribution.png",data_value_dist )
```

    ## Saving 7 x 5 in image

``` r
data_value_dist
```

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

### Problem 3

#### Load Data

``` r
#Load Data

nhanes_covar <- read_csv("nhanes_covar.csv", skip = 4)
```

    ## Rows: 250 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (5): SEQN, sex, age, BMI, education
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
nhanes_accel <- read_csv("nhanes_accel.csv")
```

    ## Rows: 250 Columns: 1441
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (1441): SEQN, min1, min2, min3, min4, min5, min6, min7, min8, min9, min1...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Organize the `covar` Dataset

``` r
#Organize the `covar` Dataset
covar_clean = nhanes_covar|>
  janitor::clean_names()|>
  mutate(
    sex = 
      case_match(
        sex,
        1 ~ "male",
        2 ~ "female"),
    sex = as.factor(sex)
      )|> #recode the numerical sex variable to factor variables;this code was borrowed from lecture notes"Tidy Data"
  mutate(
    education = 
      case_match(
        education,
        1 ~ "Less than high school",
        2 ~ "High school equivalent",
        3 ~ "More than high school"),
    education = as.factor(education)
      )|>
  filter(age >= 21)|> #filter out only participants aged 21 or 21+
  drop_na() #drop NA values
```

#### Organize the `accel` Dataset

``` r
#Organize the `accel` Dataset

accel_clean = nhanes_accel|>
  janitor::clean_names()|>
  drop_na()
```

#### Joinging Data set

``` r
# Joinging Data set
joined_dataset <- left_join(covar_clean, accel_clean, by = "seqn") 
```

The final merged data set contains all variables from the `covar` and
`accel` datasets and joined by the variable `seqn`, which appears in
both datasets.

#### Table 1: Number of Male and Female in each of the Education Category

``` r
edu_gender <- joined_dataset|>
  group_by(sex, education)|>
  drop_na()|>
  summarise(count = n(), .groups = "drop")|>
  pivot_wider(
    names_from = sex,
    values_from = count
  )|>
  knitr::kable(caption = "Number of Male and Female in Each Education Level")
```

As shown in the table, the total number of female participants who have
less than and more than high school degrees is larger than the total
number of male participants. In contrast, the total number of male
participants who have high school degrees is larger than the female
participants.

#### Visualization of the Age Distribution for Male and Female Participants

``` r
joined_clean_data <- joined_dataset|>drop_na()
age_dist = ggplot(joined_clean_data, 
       aes(x = education, y = age, color = sex)) +
       geom_boxplot()+
       labs(
         title = "Age Distribution for Education Level of Male and Female Participants",
         x = "Education Level",
         y = "Age"
       )+
  theme_minimal()
ggsave("age_disttribution.png", age_dist )  
```

    ## Saving 7 x 5 in image

``` r
age_dist
```

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-19-1.png)<!-- --> As
shown in the boxplot, the medians of age distribution in which females
who have high school or less than high school degrees are larger than
the male participants. Specifically, people who aged below 50s tend to
have higher than high school degrees, and the age distribution in which
male and female participants having less than high school degrees are
similar.

#### Total Activity Time per Participant

``` r
activity_par <- joined_clean_data|>
  group_by(seqn)|>
  pivot_longer(
    min1:min1440,
    names_to = "time",
    values_to = "activity"
  )|>
  summarise(total_activity_time = sum(activity))
```

#### Visualization of the Total Activity Time per Participant

``` r
total_activity = inner_join(joined_clean_data, activity_par, by = "seqn")|>
  relocate(seqn, sex, age, bmi, education,total_activity_time ) #binding the two dataset and relocate so we can see the total activity time more easily 
```

``` r
#Visualization
activity_plot = ggplot(total_activity, aes(x = age, y = total_activity_time, fill = sex))+
  geom_point()+
  geom_smooth()+
  labs(
    title = "Total Activity Time for Each Participant",
    x = "Age",
    y = "Total Activity Time"
  )+
  facet_grid(.~education)
ggsave("total_activity_time.png", activity_plot)
```

    ## Saving 7 x 5 in image
    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

``` r
activity_plot
```

    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-22-1.png)<!-- -->
\##### Discussion As shown in the plot above, male with high school
equivalaent and more than high school degrees generally have more
activity time compared to their female counterparts. However, female
with less than high school degrees have more activity time on average
compared to their male counterparts across the age group. For all male
and female, people who are younger than 40 years old have the most
activity time whereas the activity time dropped eminently for people
aged 60 or above.

#### Three-Panel Plot

``` r
minute = joined_clean_data|>
  pivot_longer(
    min1:min1440,
    names_to = "time",
    values_to = "activity"
  )|>
separate(time, into = c("time", "minute"), sep = 3)|>
  mutate(minute = as.numeric(minute))
```

``` r
minute_plot = ggplot(minute, aes(x = minute, y = activity, color = sex))+
  geom_smooth(se = FALSE)+
  facet_grid(.~education)+
  labs(
    title = "24 Hour Activity by Sex and Education Level",
    x = "Time in Minute",
    y = "Activity Time"
  )+
  scale_x_continuous(
    breaks = c(0, 240, 480, 720, 960, 1200, 1440)
  )+
  theme(legend.position = "bottom")
minute_plot
```

    ## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'

![](p8105_hw3_yy3439_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

``` r
ggsave("24_Hour_Activity_Time.png", minute_plot)
```

    ## Saving 7 x 5 in image
    ## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'

##### Discussion

Based on the three-panel graph, we can see that the activity time
dropped significantly from 0 to min240. Then, the activity time
increased sharply from min240 to min600 for all male and female
participants. The activity time for male and female participants with
less than high school degrees would decrease directly once past the
min600 threshold However, for male and female participants with high
school equivalent or more than high school degrees, the activity time
would fluctuate from min600 to min1200 and then decreased significantly
from min1200. In addition, female participants tend to have more
activity time on average compared to the male participants across all
education level. The three panel graph indicates that people with higher
education levels tend to be more stable and less likely to be distracted
compared to people with lower education levels.
